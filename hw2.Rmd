---
title: "p8105_hw2_xs2569"
author: "Xun Sun"
date: "2024-09-26"
output:
  github_document: null
  html_document:
    df_print: paged
---

# 1] problem 1  -  NYC Transit data

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
library(haven)
library(dplyr)
```

### 1.1 read and clean
```{r import}
subway_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |> 
  mutate( 
  entry_logic = ifelse(entry == "YES", TRUE, ifelse(entry == "NO", FALSE, NA)),
  route_count = 11 - rowSums(is.na(across(starts_with("route"), .names = "route")))) |> 
  select(line, station_name, station_latitude, station_longitude, route_count, entry_logic, vending, entrance_type, ada)

view(subway_df)
summary(subway_df)
```

##### This data frame :subway_df) now contains 9 variables as follows:
- **line** (`Character`): Indicates the subway line. 
- **station_name** (`Character`): The name of the subway station. 
- **station_latitude** (`Numeric`): The latitude coordinate of the station. Values range from 40.58 to 40.90, with a median at 40.73.
- **station_longitude** (`Numeric`): The longitude coordinate of the station. Values range from -74.03 to -73.76, with a median at -73.96.
- **route_count** (`Numeric`): The number of routes available at each station (calculated). On average, stations have about 2.29 routes available, ranging from 1 to 11.
- **entry_logic** (`Logical`): A logical indicator of whether there is an entry (`TRUE` if there is an entry, `FALSE` otherwise). 468 stations have entries marked as `TRUE`, while 1400 are marked as `FALSE`.
- **vending** (`Character`): Information about vending availability at the station. The variable contains descriptive data about vending services.
- **entrance_type** (`Character`): Type of entrance. This variable describes the type of entrance each station has.
- **ada** (`Logical`): Logical indicator for whether the station is ADA accessible (`TRUE` if accessible, `FALSE` otherwise). 468 stations are ADA accessible, while 1400 are not.

Describe data cleaning steps:
1. **Read Data**: Import the dataset, treating specific strings as NA values.
2. **Clean Column Names**: Standardize column names for consistency.
3. **Calculate Entry Logic**: Create a binary indicator for entry presence.
4. **Determine Route Count**: Compute the number of non-missing route entries per station.
5. **Select Columns**: Keep only the relevant columns.

The dimension of the resulting dataset:
The resulting data set contains 9 columns and 1868 rows. 

After the steps above, the data can still be cleaner.

### 1.2 answer questions

##### 1.2.1 How many distinct stations are there?
```{r}
n_distinct(data.frame(x = subway_df$line, y = subway_df$station_name))

unique_subway_df <- distinct(subway_df, line, station_name, .keep_all = TRUE)
view(unique_subway_df)

```

##### 1.2.2 How many stations are ADA compliant?
```{r}
sum(unique_subway_df$ada == TRUE, na.rm = TRUE)
```
##### 1.2.3 What proportion of station entrances / exits without vending allow entrance?
```{r}
A <- sum(subway_df$vending == "NO", na.rm = TRUE)
B <- sum(subway_df$vending == "NO" & subway_df$entry_logic == TRUE, na.rm = TRUE)
 B / A
```



# 2] Problem 2  -  Mr. Trash Wheel sheet

##### 2.1 Read and clean the Mr. Trash Wheel sheet
```{r message = FALSE}
MrTrash_df = 
  read_excel("./data/202309_Trash_Wheel_Collection_Data.xlsx", 
             na = c("NA", "", "."),
             sheet = "Mr. Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls)),
         year = as.double(year)) |>
  mutate(trash_wheel = "Mr. Trash Wheel") |>
  select(-x15, -x16)  # without this line the data will contain x15,x16 with all na

view(MrTrash_df)
summary(MrTrash_df)
```

##### 2.2 Read and clean Professor Trash Wheel and Gwynnda Sheet
```{r}
ProfTrash_df = 
  read_excel("./data/202309_Trash_Wheel_Collection_Data.xlsx", 
             na = c("NA", "", "."),
             sheet = "Professor Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(trash_wheel = "Professor Trash Wheel", sports_balls = 0,
         year = as.double(year))

view(ProfTrash_df)
```

```{R}
GwynTrash_df = 
  read_excel("./data/202309_Trash_Wheel_Collection_Data.xlsx", 
             na = c("NA", "", "."),
             sheet = "Gwynnda Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(trash_wheel = "Gwynnda", sports_balls = 0,
         year = as.double(year))

view(GwynTrash_df)
```

##### 2.3 Combine
```{r}
Combined_df <- bind_rows(MrTrash_df, ProfTrash_df, GwynTrash_df)
view(Combined_df)
summary(Combined_df)
```

##### 2.4 Summary 

The dataset documents the waste collection activities by three entities: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. It consists of a total of `r nrow(Combined_df)` observations, capturing monthly waste collection data from 2014 to 2023.

**Key Variables:**
- **Dumpster ID** (`dumpster`): Identifies the dumpster number, with a minimum of 1 and a maximum of 584.
- **Month and Year** (`month`, `year`): Character strings indicating the time of collection, with the earliest record starting in 2014 and the latest in 2023.
- **Date** (`date`): Provides a precise timestamp of the waste collection.

**Waste Collection Metrics:**
- **Weight** (`weight_tons`): Records the weight of the waste collected, ranging from 0.610 tons to a maximum of 5.620 tons, with an average collection weight of approximately 3.009 tons.
- **Volume** (`volume_cubic_yards`): Indicates the volume of waste in cubic yards, with values ranging from 5 to 20, and an average volume of 15.13 cubic yards.

**Types of Waste Materials:**
- **Plastic Bottles** (`plastic_bottles`): The minimum collected was 0, with a median of 1980 and an average of 2296.
- **Polystyrene** (`polystyrene`): Collected amounts range from 0 to 11528, averaging 1631.
- **Cigarette Butts** (`cigarette_butts`): The minimum collected was 0, with a median of 5500 and an average of 15592.
- **Glass Bottles** (`glass_bottles`): Collected amounts range from 0 to 110, averaging 20.89.
- **Plastic Bags** (`plastic_bags`): The minimum collected was 0, with a median of 1380 and an average of 2330.
- **Wrappers** (`wrappers`): Collected amounts range from 180 to 20100, averaging 9.102.

**Additional Information:**
- **Sports Balls** (`sports_balls`): The minimum collected was 0, with a median of 6 and an average of 9.102.
- **Homes Powered** (`homes_powered`): Estimates the number of homes that could be powered by the energy equivalent of the waste collected, with a median of 49.50 and an average of 45.87.

The minimum and maximum weights of trash collected are `r round(min(Combined_df$weight_tons, na.rm = TRUE), 2)` tons and `r round(max(Combined_df$weight_tons, na.rm = TRUE), 2)` tons, respectively. The median number of `plastic_bottles` collected is `r median(Combined_df$plastic_bottles, na.rm = TRUE)`, and the mean number of `cigarette_butts` is `r mean(Combined_df$cigarette_butts, na.rm = TRUE)`.

```{r echo=FALSE}
# Calculate minimum and maximum weights of trash collected
min_weight <- min(Combined_df$weight_tons, na.rm = TRUE)
max_weight <- max(Combined_df$weight_tons, na.rm = TRUE)

# Calculate median number of plastic bottles collected
median_plastic_bottles <- median(Combined_df$plastic_bottles, na.rm = TRUE)

# Calculate mean number of cigarette butts collected
mean_cigarette_butts <- mean(Combined_df$cigarette_butts, na.rm = TRUE)

# Create a data frame to store the results
results <- data.frame(
  Min_Weight = min_weight,
  Max_Weight = max_weight,
  Median_Plastic_Bottles = median_plastic_bottles,
  Mean_Cigarette_Buts = mean_cigarette_butts
)

# Print the results
print(results)

```

The total weight of trash collected by Professor Trash Wheel can be calculated as follows:
```{r}
sum(ProfTrash_df$weight_tons)
```

The total number of cigarette_butts collected by Gwynnda in June 2022 can be calculated by first filtering the data for the specified conditions and then summing up the cigarette_butts:
```{r}
sum(GwynTrash_df$cigarette_butts[GwynTrash_df$month == "June" & GwynTrash_df$year == "2022"])
```
# 3] Problem 3  -  Great British Bake Off

##### 3.1 Read and clean the data

```{r}
bakers_df = 
  read.csv("./data/bakers.csv", 
             na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  mutate(baker = word(baker_name, 1))
view(bakers_df)

bakes_df = 
  read.csv("./data/bakes.csv", 
             na = c("NA", "", ".")) |>
  janitor::clean_names() 
view(bakes_df)

results_df = 
  read.csv("./data/results.csv", 
             na = c("NA", "", "."),
             skip = 2) |>
  janitor::clean_names() 
view(results_df)
```

##### 3.2  Check for completeness 
```{r,warning=FALSE}

anti_join(bakes_df, bakers_df, by = "baker")


anti_join(bakers_df, bakes_df, by = "baker")


anti_join(results_df, bakers_df, by = "baker")


anti_join(bakers_df, results_df, by = "baker")


anti_join(bakes_df, results_df, by = c("baker","series"))


anti_join(results_df, bakes_df, by = c("baker","series"))
```

##### 3.3  join 
```{r}

# join bakes and bakers
bakes_bakers = full_join(bakers_df, bakes_df,by = c("series","baker"))
# join bake_bakers with result
final_dataset = full_join(bakes_bakers, results_df, by = c("baker", "series", "episode"))
view(final_dataset)
```

##### 3.4 rearrange and export
```{r}
final_df = final_dataset |>
  select(series, episode, baker_name, baker, result, everything()) |>
  arrange(series,episode,baker_name)
view(final_df)


write.csv(final_df, "final_bake_data.csv", row.names = FALSE)
```

##### 3.5# 3] Problem 3  -  Great British Bake Off

##### 3.1 Read and clean the data

```{r}
bakers_df = 
  read.csv("./data/bakers.csv", 
             na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  mutate(baker = word(baker_name, 1))
view(bakers_df)

bakes_df = 
  read.csv("./data/bakes.csv", 
             na = c("NA", "", ".")) |>
  janitor::clean_names() 
view(bakes_df)

results_df = 
  read.csv("./data/results.csv", 
             na = c("NA", "", "."),
             skip = 2) |>
  janitor::clean_names() 
view(results_df)
```

##### 3.2  Check for completeness 
```{r,warning=FALSE}

anti_join(bakes_df, bakers_df, by = "baker")


anti_join(bakers_df, bakes_df, by = "baker")


anti_join(results_df, bakers_df, by = "baker")


anti_join(bakers_df, results_df, by = "baker")


anti_join(bakes_df, results_df, by = c("baker","series"))


anti_join(results_df, bakes_df, by = c("baker","series"))
```

##### 3.2  join 
```{r}

# join bakes and bakers
bakes_bakers = full_join(bakers_df, bakes_df,by = c("series","baker"))
# join bake_bakers with result
final_dataset = full_join(bakes_bakers, results_df, by = c("baker", "series", "episode"))
view(final_dataset)
```

##### 3.3 rearrange and export
```{r}
final_df = final_dataset |>
  select(series, episode, baker_name, baker, result, everything()) |>
  arrange(series,episode,baker_name)
view(final_df)


write.csv(final_df, "final_bake_data.csv", row.names = FALSE)
```

